{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the right data file format for numerical computing\n",
    "\n",
    "This notebook will go over the pros and cons of various data file formats common in numerical python workflows. It'll cover various concerns when storing data on-disk and how popular formats address these challenges; the what and why of these formats.\n",
    "\n",
    "## Who am I?\n",
    "\n",
    "* David Hoese <sub>pronounced like Haze</sub>\n",
    "* Software Developer (Sr. Instrumentation Technologist)<br>\n",
    "  Space Science and Engineering Center (SSEC)<br>\n",
    "  University of Wisconsin - Madison\n",
    "* Satpy and Vispy developer\n",
    "* @djhoese on Twitter and GitHub\n",
    "\n",
    "## Contents\n",
    "\n",
    "TODO\n",
    "\n",
    "## Why write data to disk?\n",
    "\n",
    "1. State or Cache\n",
    "   * a long running application needs to start where it left off\n",
    "   * reuse calculation in future executions\n",
    "   * user settings/preferences are saved for later use\n",
    "2. Data Archival/Distribution/Sharing\n",
    "   * results are shared with other people\n",
    "   * results are shared with other software\n",
    "\n",
    "## What kind of files are we working with?\n",
    "\n",
    "* Plain text or binary file formats\n",
    "* Primarily numeric data\n",
    "* Optionally add custom metadata\n",
    "\n",
    "## What are we **NOT** talking about?\n",
    "\n",
    "* Databases\n",
    "* Python's pickle format\n",
    "* Storing user application settings\n",
    "* **Custom** binary formats (no community/organization support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why does file format matter?\n",
    "\n",
    "There are many different formats that we can use in Python and we have\n",
    "different ways to access them. Each one comes with various advantages and\n",
    "disadvantages. When it comes to choosing a file format for a task we should\n",
    "be concerned with a few key things:\n",
    "\n",
    "* **Write speeds**<br>\n",
    "  How long does it take to get data from it's in-memory format to disk?\n",
    "* **Read speeds**<br>\n",
    "  How long does it take to get data from disk to a usable in-memory format?\n",
    "* **On-disk size**<br>\n",
    "  How big are the files?\n",
    "* **In-memory size**<br>\n",
    "  How much memory does it take to open the file and get data out? Are there multiple copies of the data in memory?\n",
    "* **Flexibility/Usefulness**<br>\n",
    "  Can I do anything else with the format? Store metadata? Can I use it for this other use case? Can I lazily load data? Can I access data remotely? Can I compress the data? How much data can I store in one file?\n",
    "* **Format Availability**<br>\n",
    "  Is the format only readable by Python software? Do my users need to learn something new to read it? If the format isn't \"built in\" to a programming environment, can I easily install the necessary libraries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup - Plain Text\n",
    "\n",
    "Let's start with an example that uses plain text to write the last time that\n",
    "the function was called. We first need to import a few modules and then\n",
    "create our function to append to our data file called `last_time.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "DATA_FILE = 'last_time.txt'\n",
    "\n",
    "def write_time():\n",
    "    with open(DATA_FILE, 'a') as time_file:\n",
    "        now = datetime.utcnow()\n",
    "        data_line = \"{:f}\\n\".format(now.timestamp())\n",
    "        time_file.write(data_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our function we get the current time in\n",
    "[UTC](https://en.wikipedia.org/wiki/Coordinated_Universal_Time). We convert\n",
    "it to epoch time (a.k.a. POSIX time), seconds since `1970-01-01 00:00:00`, and\n",
    "write the string representation to the file as a single line.\n",
    "\n",
    "Let's add a couple times to the file by running the `write_time` a couple\n",
    "times below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use the command `head` to print out the first couple lines of the file's contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1568667832.827468\n",
      "1568667832.827796\n",
      "1568667832.827835\n",
      "1568667832.827897\n",
      "1568667832.827929\n",
      "1568667832.827957\n",
      "1568667832.827985\n",
      "1568667832.828037\n",
      "1568667832.828065\n",
      "1568667832.828094\n"
     ]
    }
   ],
   "source": [
    "!head $DATA_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've written data to the file, now let's read it back out. The below function\n",
    "will read the content's of the file in to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_times():\n",
    "    exec_times = []\n",
    "    with open(DATA_FILE, 'r') as time_file:\n",
    "        for line in time_file:\n",
    "            time_val = float(line.strip())\n",
    "            exec_times.append(time_val)\n",
    "    return exec_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1568667832.827468,\n",
       " 1568667832.827796,\n",
       " 1568667832.827835,\n",
       " 1568667832.827897,\n",
       " 1568667832.827929,\n",
       " 1568667832.827957,\n",
       " 1568667832.827985,\n",
       " 1568667832.828037,\n",
       " 1568667832.828065,\n",
       " 1568667832.828094]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_times()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above gives us a simple example of saving data from software to a\n",
    "file on disk. We wrote a single value at a time and accumulate more\n",
    "information as time went on. We were able to read these data back\n",
    "in to python at a later time. Could we have done anything differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain Text - Pros/Cons\n",
    "\n",
    "Let's take the above concerns and look at our text file from before and the\n",
    "code we used to access it.\n",
    "\n",
    "<details>\n",
    "<summary>Pros</summary>\n",
    "    \n",
    "* Human readable\n",
    "* Simple code (no external libraries)\n",
    "* Easily usable by other languages/tools\n",
    "* Could read one value at a time (but we didn't)\n",
    "    \n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Cons</summary>\n",
    "\n",
    "* Have to convert data to/from string and float (slow)\n",
    "* Representing each 8 byte float (64-bit) as ~17 ASCII bytes\n",
    "* Unknown precision of data values, how many decimal points?\n",
    "* Don't know how many elements until it is fully read\n",
    "* Can't easily seek to a specific index/element\n",
    "* Code: Read as a list instead of a numpy array and used a python for loop (potentially slow)\n",
    "    \n",
    "</details>\n",
    "<br>\n",
    "\n",
    "And here's what a single value of our text file looks like on disk (8-bit ASCII character):\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Byte Offset</th>\n",
    "        <th>Value</th>\n",
    "    </tr>\n",
    "    <tr><td>0</td><td>1</td></tr>\n",
    "    <tr><td>1</td><td>5</td></tr>\n",
    "    <tr><td>2</td><td>6</td></tr>\n",
    "    <tr><td>3</td><td>8</td></tr>\n",
    "    <tr><td>4</td><td>6</td></tr>\n",
    "    <tr><td>5</td><td>6</td></tr>\n",
    "    <tr><td>6</td><td>7</td></tr>\n",
    "    <tr><td>7</td><td>8</td></tr>\n",
    "    <tr><td>8</td><td>3</td></tr>\n",
    "    <tr><td>9</td><td>2</td></tr>\n",
    "    <tr><td>10</td><td>.</td></tr>\n",
    "    <tr><td>11</td><td>8</td></tr>\n",
    "    <tr><td>12</td><td>2</td></tr>\n",
    "    <tr><td>13</td><td>7</td></tr>\n",
    "    <tr><td>14</td><td>4</td></tr>\n",
    "    <tr><td>15</td><td>6</td></tr>\n",
    "    <tr><td>16</td><td>8</td></tr>\n",
    "    <tr><td>17</td><td>\\n</td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a quick timing to see how long it takes to read the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.8 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "txt_time_write = %timeit -o -n 10000 -r 1 write_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.73 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "txt_time_read = %timeit -o -n 100 -r 1 read_times()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy library also provides a function for loading data from text files.\n",
    "Let's try it and see how it compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.1 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "txt_time_read_np = %timeit -o -n 100 -r 1 np.loadtxt(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that in this specific case and with all of the extra checks numpy\n",
    "performs, it actually takes longer to read the data with numpy. When it comes\n",
    "to simple human-readable formats, we couldn't have gone much simpler.\n",
    "\n",
    "The remainder of this document will go through different use cases and\n",
    "the file formats that we have as options. We'll apply this type of\n",
    "performance analysis to our format choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Binary\n",
    "\n",
    "When human-readability isn't necessary, another option for storing simple\n",
    "data structures is a flat binary file. A flat binary file consists of the\n",
    "raw data values stored contiguously as a flat array. Let's rewrite our code\n",
    "from above to write to a flat binary file using the numpy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "BIN_DATA_FILE = 'last_time.dat'\n",
    "\n",
    "def write_time_binary():\n",
    "    with open(BIN_DATA_FILE, 'a') as time_file:\n",
    "        now = datetime.utcnow()\n",
    "        np.array([now.timestamp()], dtype=np.float64).tofile(time_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_times_binary():\n",
    "     return np.fromfile(BIN_DATA_FILE, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.1 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "bin_time_write = %timeit -o -n 100000 -r 1 write_time_binary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.2 µs ± 13.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "bin_time_read = %timeit -o -n 100 -r 7 read_times_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Tip: Memory Maps\n",
    "\n",
    "By default, when reading a file from disk we have to transfer data from\n",
    "the hard disk to system memory. That means that when creating something\n",
    "like a numpy array from a binary data file we are transferring **all** of the\n",
    "file's contents from disk in to memory when we might not use it right away; a very slow operation. There is a\n",
    "lazier, generally more efficient, method called memory mapping (a.k.a. mmap in\n",
    "C, memmap by numpy). By creating a memory map, we allocate the virtual memory\n",
    "space for our data, but the operating system won't load the data from disk\n",
    "until we need it. Memory mapping avoids extra copies of file data in memory, works very well with random accesses to data in a file, can be cached more efficiently, shared between processes more effectively, and is generally your best option for reading large files that are difficult to hold in memory at a single time.\n",
    "\n",
    "Further reading:\n",
    "\n",
    "* [Stackoverflow answer discussing memory maps](https://stackoverflow.com/a/6383253/433202)\n",
    "* [Memory-mapped File - Wikipedia](https://en.wikipedia.org/wiki/Memory-mapped_file)\n",
    "\n",
    "Going back to the above binary file usage..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_times_binary_memmap():\n",
    "    return np.memmap(BIN_DATA_FILE, mode='r', dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.4 µs ± 7.57 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "bin_time_read_mmap = %timeit -o -n 100 -r 7 read_times_binary_memmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1368372537238214"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_time_read.average / bin_time_read_mmap.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that memory mapping isn't **loading** the data in to memory so this isn't technically a fair comparison. However, as we use the memory mapped array object we should see better performance than a traditional read of the file.\n",
    "\n",
    "Note that we could also use memory maps to write data. This is most beneficial if we are writing to random locations in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Binary - Pros/Cons\n",
    "\n",
    "<details>\n",
    "    <summary>Pros</summary>\n",
    "    \n",
    "* Simple code\n",
    "* Readable by any programming language (*see Cons)\n",
    "* Minimum on-disk size without compression\n",
    "* Fast reading and memory mappable\n",
    "* Supports N-dimensional data\n",
    "* Subsettable\n",
    "\n",
    "</details>\n",
    "    \n",
    "<details>\n",
    "    <summary>Cons</summary>\n",
    "    \n",
    "* Not human readable\n",
    "* No shape, data type, or byte order information stored\n",
    "* Platform dependent (not shareable)\n",
    "\n",
    "Note from numpy docs:\n",
    "    \n",
    "> Do not rely on the combination of tofile and fromfile for data storage, as the binary files generated are are not platform independent. In particular, no byte-order or data-type information is saved. Data can be stored in the platform independent .npy format using save and load instead.\n",
    "    \n",
    "</details>\n",
    "\n",
    "Storage layout (64-bit float):\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Byte Offset</th>\n",
    "        <th>Value</th>\n",
    "    </tr>\n",
    "    <tr><td>0</td><td>1568667832.827468</td></tr>\n",
    "    <tr><td>8</td><td>1568667832.827796</td></tr>\n",
    "    <tr><td>16</td><td>1568667832.827835</td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus - Numpy's .npy format\n",
    "\n",
    "As mention in the cons above, a flat binary file *only* has the data and no\n",
    "other information. This means we have to keep track of this information\n",
    "ourselves. To help with this numpy provides a `.npy` format which stores this\n",
    "information inside the file alongside the binary data. Here's a quick example\n",
    "to create a `.npy` file using\n",
    "[`np.save`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html#numpy.save)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('last_time.npy', np.array([1., 2., 3.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are ready to read the data back we can use\n",
    "[`np.load`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html#numpy.load).\n",
    "This method gives us the option to open the data as a memory map, giving us\n",
    "the space and speed advantages of a flat binary while avoiding the format\n",
    "metadata issues. Keep in mind that this format is only readable by numpy and\n",
    "would require an additional library in any other language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([1., 2., 3.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('last_time.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comma-Separated Values (CSV)\n",
    "\n",
    "So far we've dealt with a single stream (a.k.a. field or variable) of data,\n",
    "but what if we need to store more? When it comes to multiple 1-dimensional\n",
    "variables one of the more common solutions is a Comma-Separate Values (CSV)\n",
    "file. We could use numpy again, but instead we'll use the `pandas` library\n",
    "for its more powerful handling of tabular data like we would store in a CSV.\n",
    "\n",
    "We'll start by loading some example data used by the seaborn python package.\n",
    "Their example data is stored as a\n",
    "[CSV file on GitHub](https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv).\n",
    "We use the pandas\n",
    "[`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "function. This function has a lot of options, but we'll use the defaults for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seaborn_iris_url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
    "data = pd.read_csv(seaborn_iris_url)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were making our CSV file from a pandas dataframe we can use `to_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.518009</td>\n",
       "      <td>0.625533</td>\n",
       "      <td>0.663213</td>\n",
       "      <td>0.752765</td>\n",
       "      <td>0.985216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.176046</td>\n",
       "      <td>0.204976</td>\n",
       "      <td>0.907754</td>\n",
       "      <td>0.967893</td>\n",
       "      <td>0.398528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.774760</td>\n",
       "      <td>0.296300</td>\n",
       "      <td>0.530271</td>\n",
       "      <td>0.627792</td>\n",
       "      <td>0.819883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.614117</td>\n",
       "      <td>0.114465</td>\n",
       "      <td>0.713061</td>\n",
       "      <td>0.716801</td>\n",
       "      <td>0.926176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.099838</td>\n",
       "      <td>0.023641</td>\n",
       "      <td>0.082771</td>\n",
       "      <td>0.523411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E\n",
       "0  0.518009  0.625533  0.663213  0.752765  0.985216\n",
       "1  0.176046  0.204976  0.907754  0.967893  0.398528\n",
       "2  0.774760  0.296300  0.530271  0.627792  0.819883\n",
       "3  0.614117  0.114465  0.713061  0.716801  0.926176\n",
       "4  0.198582  0.099838  0.023641  0.082771  0.523411"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.DataFrame(np.random.random((150, 5)), columns=['A', 'B', 'C', 'D', 'E'])\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.to_csv('randoms.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also provides options for memory mapping the text file to reduce I/O\n",
    "overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.518009</td>\n",
       "      <td>0.625533</td>\n",
       "      <td>0.663213</td>\n",
       "      <td>0.752765</td>\n",
       "      <td>0.985216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.176046</td>\n",
       "      <td>0.204976</td>\n",
       "      <td>0.907754</td>\n",
       "      <td>0.967893</td>\n",
       "      <td>0.398528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.774760</td>\n",
       "      <td>0.296300</td>\n",
       "      <td>0.530271</td>\n",
       "      <td>0.627792</td>\n",
       "      <td>0.819883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.614117</td>\n",
       "      <td>0.114465</td>\n",
       "      <td>0.713061</td>\n",
       "      <td>0.716801</td>\n",
       "      <td>0.926176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.099838</td>\n",
       "      <td>0.023641</td>\n",
       "      <td>0.082771</td>\n",
       "      <td>0.523411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E\n",
       "0  0.518009  0.625533  0.663213  0.752765  0.985216\n",
       "1  0.176046  0.204976  0.907754  0.967893  0.398528\n",
       "2  0.774760  0.296300  0.530271  0.627792  0.819883\n",
       "3  0.614117  0.114465  0.713061  0.716801  0.926176\n",
       "4  0.198582  0.099838  0.023641  0.082771  0.523411"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.read_csv('randoms.csv', memory_map=True)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Tip: Chunking\n",
    "\n",
    "So far we've been loading all data at once or depending on memory mapping to\n",
    "reduce the amount of data that was loaded at any one time. Another possible\n",
    "improvement can come from loading chunks of data at a time. This is similar\n",
    "to what we did with the original plain text file iterating over the lines of\n",
    "the file one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By chunking and iterating over the data we can process files that would not\n",
    "fit in memory otherwise. For more info on chunking, see the\n",
    "[pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#iterating-through-files-chunk-by-chunk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D         E\n",
      "0  0.518009  0.625533  0.663213  0.752765  0.985216\n",
      "1  0.176046  0.204976  0.907754  0.967893  0.398528\n",
      "2  0.774760  0.296300  0.530271  0.627792  0.819883\n",
      "3  0.614117  0.114465  0.713061  0.716801  0.926176\n",
      "          A         B         C         D         E\n",
      "4  0.198582  0.099838  0.023641  0.082771  0.523411\n",
      "5  0.451134  0.288878  0.599627  0.101376  0.254136\n",
      "6  0.652017  0.752561  0.262403  0.144780  0.932307\n",
      "7  0.910469  0.449665  0.533842  0.230622  0.112332\n",
      "           A         B         C         D         E\n",
      "8   0.588053  0.131510  0.093826  0.441200  0.665580\n",
      "9   0.118112  0.783991  0.766641  0.014607  0.263812\n",
      "10  0.453678  0.411469  0.183099  0.631480  0.020634\n",
      "11  0.383354  0.166245  0.382711  0.222890  0.618206\n"
     ]
    }
   ],
   "source": [
    "reader = pd.read_csv('randoms.csv', iterator=True, chunksize=4)\n",
    "for idx, chunk_df in enumerate(reader):\n",
    "    print(chunk_df)\n",
    "    if idx >= 2: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reduces the amount of memory being used at any one time while we work with a single chunk.\n",
    "\n",
    "We can change how big of a chunk we get by calling `get_chunk` with the number of\n",
    "rows to put in the DataFrame returned. Note how we are continuing our reading from the above cells since the reader is an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.443357</td>\n",
       "      <td>0.632036</td>\n",
       "      <td>0.785462</td>\n",
       "      <td>0.580356</td>\n",
       "      <td>0.150587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.282351</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.887258</td>\n",
       "      <td>0.058430</td>\n",
       "      <td>0.382341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.526052</td>\n",
       "      <td>0.213249</td>\n",
       "      <td>0.617271</td>\n",
       "      <td>0.985686</td>\n",
       "      <td>0.174114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.813454</td>\n",
       "      <td>0.314126</td>\n",
       "      <td>0.668044</td>\n",
       "      <td>0.504940</td>\n",
       "      <td>0.875045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.521319</td>\n",
       "      <td>0.684906</td>\n",
       "      <td>0.575570</td>\n",
       "      <td>0.085062</td>\n",
       "      <td>0.889112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.445894</td>\n",
       "      <td>0.196311</td>\n",
       "      <td>0.277273</td>\n",
       "      <td>0.387277</td>\n",
       "      <td>0.006089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A         B         C         D         E\n",
       "18  0.443357  0.632036  0.785462  0.580356  0.150587\n",
       "19  0.282351  0.008892  0.887258  0.058430  0.382341\n",
       "20  0.526052  0.213249  0.617271  0.985686  0.174114\n",
       "21  0.813454  0.314126  0.668044  0.504940  0.875045\n",
       "22  0.521319  0.684906  0.575570  0.085062  0.889112\n",
       "23  0.445894  0.196311  0.277273  0.387277  0.006089"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.get_chunk(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV - Pros/Cons\n",
    "\n",
    "<details>\n",
    "    <summary>Pros</summary>\n",
    "\n",
    "* Human readable\n",
    "* Can be read in Microsoft Excel (non-programmer collaboration)\n",
    "* Lazy/iterable loading possible\n",
    "* Row-based operations are relatively fast\n",
    "\n",
    "</details>\n",
    "    \n",
    "<details>\n",
    "    <summary>Cons</summary>\n",
    "\n",
    "* Slow to read/write\n",
    "* Wasted disk space\n",
    "* Require reading all columns to get value for a single column\n",
    "* Column-based operations are slow (see below)\n",
    "\n",
    "</details>\n",
    "\n",
    "An unfortunate storage layout for a 3 column CSV (8-bit ASCII characters):\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Byte Offset</th>\n",
    "        <th>Value</th>\n",
    "        <th>Column</th>\n",
    "    </tr>\n",
    "    <tr><td>0</td><td>0.4433,</td><td>1</td></tr>\n",
    "    <tr><td>7</td><td>0.623,</td><td>2</td></tr>\n",
    "    <tr><td>13</td><td>setosa\\n</td><td>3</td></tr>\n",
    "    <tr><td>20</td><td>0.8866,</td><td>1</td></tr>\n",
    "    <tr><td>27</td><td>0.31,</td><td>2</td></tr>\n",
    "    <tr><td>32</td><td>virginica\\n</td><td>3</td></tr>\n",
    "    <tr><td>42</td><td>0.6644,</td><td>1</td></tr>\n",
    "    </table>\n",
    "\n",
    "The above table shows how a CSV file may be stored on disk. If we don't force all floating point numbers to have the same number of digits or string fields are not all the same size then we can't be sure how to quickly get all values for a single column (by calculating offsets) without reading every value for every column. This makes doing column-based calculations, like the average of an entire field, very slow and wasteful. If we are doing a calculation that requires all values in a single row, then this structure is fairly convenient; we can parse one row at a time efficiently.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "* [Dask DataFrames](https://docs.dask.org/en/latest/dataframe.html) for distributed and lazy pandas dataframes\n",
    "\n",
    "## Review 1\n",
    "\n",
    "* Store as text: Human-readable but slow\n",
    "* Store as binary: Easily indexable and fast to read/write\n",
    "* Memory maps: Better I/O in most cases\n",
    "* Chunking: Good when working on one chunk at a time\n",
    "* Flat binary: Simple, quick solution, multiple dimensions, no structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet\n",
    "\n",
    "Parquet is another tabular data format and can be thought of as the high\n",
    "performance binary version of the CSV file.\n",
    "Analytics workflows typically don't need to read every column from a tabular\n",
    "format and storing data in something like a CSV file can be very wasteful.\n",
    "The first difference in what Parquet brings to the table (pun intended) is storing data by\n",
    "column (image right) instead of by row (image left).\n",
    "\n",
    "<img src=\"https://www.kdnuggets.com/wp-content/uploads/dremio-table-1.jpg\">\n",
    "<center><sub>Credit: https://www.kdnuggets.com/2017/02/apache-arrow-parquet-columnar-data.html</sub></center>\n",
    "<br>\n",
    "\n",
    "If we keep the columns together it is easier to access one column more easily\n",
    "and more quickly than data stored row by row.\n",
    "\n",
    "## Performance Tip: Spatial and Temporal Locality\n",
    "\n",
    "Modern CPUs have multiple levels of caching. The closer a cache level is to the CPU (the computation) the smaller it is and less it can store at any one time. These closer cache levels are also much faster to get data from. Conversely, caches that are further from the CPU are larger and slower to access. The diagram shows the various caching levels common in modern computers where L1 caches are the smallest and fastest, then L2, L3, main RAM memory, and finally the hard disk; the largest and slowest storage on the local machine. \n",
    "\n",
    "<img width=\"400px\" src=\"https://softwarerajivprab.files.wordpress.com/2019/07/cache.png\" alt=\"CPU L1 L2 L3 cache diagram\">\n",
    "<center><sub>Credit: https://software.rajivprab.com/2018/04/29/myths-programmers-believe-about-cpu-caches/</sub></center><br>\n",
    "\n",
    "If we want the best performance out of the file format we are using then we want to do as many operations as possible with what is in the L1 cache before replacing it with new data. Otherwise, we could suffer from reloading the same data from slower caches. **Temporal locality** is the idea that if we access a particular memory location, we are very likely to access that same location again in the near future. **Spatial locality** is the idea that if we access a particular memory location, an operation in the near future is probably going to involve the data right next to it. Modern computers will assume this to be true and will predictively cache things to get the best performance. That means our best option is to use the memory the way the computer thinks we are going to use it.\n",
    "\n",
    "## Performance Tip: Block sizes\n",
    "\n",
    "Each storage device (cache, RAM, disk) will typically have a default size or \"chunk\" of data that it will operate on or store in one contiguous location or provide to another storage element.\n",
    "\n",
    "Further Reading: [Wikipedia](https://en.wikipedia.org/wiki/Locality_of_reference)\n",
    "\n",
    "## Performance Tip: Single Instruction, Multiple Data (SIMD)\n",
    "\n",
    "In addition to the multiple cache levels, modern CPUs can also operate on multiple pieces of data at the same time with a single CPU instruction. These vectorized instructions are referred to as SIMD. The CPU is told to do one operation on many values (ex. add 5 to every value) and can perform it on multiple values at a time, in parallel. \n",
    "\n",
    "Even though SIMD instructions are low-level, NumPy does a lot of the work for us by telling the CPU to use SIMD instructions when possible. However, this usually depends on taking advantage of locality (see above) so that the CPU has all the values it is going to operate on.\n",
    "\n",
    "Further Reading: [Wikipedia](https://en.wikipedia.org/wiki/SIMD)\n",
    "\n",
    "<br>\n",
    "\n",
    "Parquet's design for how data is stored on disk and operated on in-memory tries to take advantage of these concepts. Let's run through a basic parquet example to see how we can read and write a parquet file and how we can control some aspects of these complex topics. We'll start by reusing the seaborn sample data from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seaborn_iris_url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
    "data = pd.read_csv(seaborn_iris_url)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write this data to a local parquet file using the `fastparquet` library (there are others):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastparquet as fp\n",
    "fp.write('iris1.parq', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 davidh davidh 8.4K Oct  7 21:18 iris1.parq\n"
     ]
    }
   ],
   "source": [
    "!ls -lh iris1.parq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parq_file = fp.ParquetFile('iris1.parq')\n",
    "parq_file.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default fastparquet makes a single file with no compression and only stores entire columns together (no row-groups). Although these defaults may not provide the best performance for a particular use case, the format itself provides us some nice conviences. For example, since the data is stored by column we can quickly and efficiently load a limited set of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal_length  petal_width\n",
       "0           1.4          0.2\n",
       "1           1.4          0.2\n",
       "2           1.3          0.2\n",
       "3           1.5          0.2\n",
       "4           1.4          0.2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = parq_file.to_pandas(['petal_length', 'petal_width'])\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
